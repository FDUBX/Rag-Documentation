# Configuration du système RAG

# Chemins des répertoires
paths:
  data_dir: "./data"              # Dossier contenant les documents à indexer
  vectorstore_dir: "./vectorstore" # Dossier pour le vector store
  urls_file: "./vectorstore/indexed_urls.json"  # Fichier de sauvegarde des URLs indexées

# Paramètres de découpage des documents
chunking:
  chunk_size: 1000                # Taille des chunks en caractères
  chunk_overlap: 200              # Chevauchement entre chunks

# Paramètres de recherche
search:
  top_k: 5                        # Nombre de chunks à récupérer

# Modèles
models:
  embedding_model: "mxbai-embed-large"  # Modèle d'embedding Ollama
  generation_model: "llama3.2"          # Modèle de génération Ollama
  temperature: 0.7                      # Température pour la génération
  max_tokens: 1024                       # Nombre maximum de tokens

# Configuration de l'interface web
web:
  host: "0.0.0.0"
  port: 5000
  debug: true                    # Mode debug (affiche les erreurs détaillées) - surchargé par FLASK_ENV=production
  use_reloader: false           # Désactive le rechargement automatique (évite le double démarrage)

# Configuration Ollama
ollama:
  timeout: 120                   # Timeout en secondes pour les appels Ollama (génération LLM)
  base_url: "http://localhost:11434"  # URL de base d'Ollama
  # Note: Les timeouts pour les embeddings sont gérés par la bibliothèque requests

# Configuration du logging
logging:
  level: "INFO"                  # Niveau de log: DEBUG, INFO, WARNING, ERROR, CRITICAL
  file: "./logs/app.log"         # Fichier de log (None pour désactiver)
  max_bytes: 10485760            # Taille max du fichier de log (10MB)
  backup_count: 5                # Nombre de fichiers de backup

# Configuration pour le chargement de pages web
web_loader:
  user_agent: "RAG-Documentation/1.0 (https://github.com/your-repo/rag-documentation)"  # User-Agent pour les requêtes HTTP

